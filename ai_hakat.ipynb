{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n%load_ext autoreload\n\n%autoreload 2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a kaggle data set. The images are high resolution chest x-ray images. \n\nClass descriptions\nThere are 15 classes (14 diseases, and one for \"No findings\"). Images can be classified as \"No findings\" or one or more disease classes:\n\nAtelectasis\nConsolidation\nInfiltration\nPneumothorax\nEdema\nEmphysema\nFibrosis\nEffusion\nPneumonia\nPleural_thickening\nCardiomegaly\nNodule Mass\nHernia\n\n62 thousand imagesare used are used in this notebook.\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dir =  \"/kaggle/input/data\"\ntrain = os.listdir(\"/kaggle/input/data\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image1 =  os.path.join(dir + \"images_001\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from glob import glob \nimport pandas as pd\n\ndataset = pd.read_csv('../input/data/Data_Entry_2017.csv')\npaths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..', 'input', 'data',  'images*', '*', '*.png'))}\nprint('Scans found:', len(paths), ', Total Headers', dataset.shape[0])\ndataset['path'] = dataset['Image Index'].map(paths.get)\ndataset['Cardiomegaly'] = dataset['Finding Labels'].map(lambda x: 'Cardiomegaly' in x)\ndataset['Finding'] = dataset['Finding Labels'].map(lambda x: x != 'No Finding').astype(int)\ndataset['Patient Age'] = np.clip(dataset['Patient Age'], 5, 100)\nlabel_freq = dataset['Finding Labels'].apply(lambda s: str(s).split('|')).explode().value_counts().sort_values(ascending=False)\nrare = list(label_freq[label_freq<10].index)\ndataset['labels'] = dataset['Finding Labels'].apply(lambda s: [l for l in str(s).split('|') if l not in rare])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dataset['Finding Labels'] = dataset['Finding Labels'].map(lambda x: x.replace('No Finding', 'n'))\nfrom itertools import chain\nall_labels = np.unique(list(chain(*dataset['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nall_labels = [x for x in all_labels if len(x)>0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        dataset[c_label] = dataset['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\n#dataset.sample(3)\ndataset['disease_vec'] = dataset.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = dataset[['Image Index' , 'Patient ID', 'path', 'Finding' , 'labels' , 'disease_vec']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"noFind = data[data['Finding']==0]['Image Index'].tolist()\nFind = data[data['Finding']==1]['Image Index'].tolist()\nnoFind_path = data[data['Finding']==0]['path'].tolist()\nFind_path = data[data['Finding']==1]['path'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = (glob(os.path.join('..' , 'input' , 'data' , 'images*' , '*' , '*' )))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #noFind_paths = []\n# #for i in noFind[:10000]:\n#     destination = (glob(os.path.join('..' , 'input' , 'data' , 'images*' , '*' , i )))\n#     noFind_paths.append(destination)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find_paths = []\n# for i in Find:\n#     destination = (glob(os.path.join('..' , 'input' , 'data' , 'images*' , '*' , i )))\n#     Find_paths.append(destination)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_paths = Find_path + noFind_path[:10000]\n\nfinal_data = data[data['Finding']==1]\ntemp= data[data['Finding']==0][:10000]\n\n\nfinal_data.append(temp)\nfinal_paths = final_data['path'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\ntrain_df, valid_df , train_y , valid_y = train_test_split(final_paths, \n                                                          final_data['disease_vec'].tolist(),\n                                   test_size = 0.6, \n                                   random_state = 2000,\n                                   #stratify = data['labels'].map(lambda x: x[:4]\n                                     )\n\nvalid_df, test_df , valid_y , test_y = train_test_split(valid_df, \n                                                        valid_y,\n                                   test_size = 0.5, \n                                   random_state = 2000)\n\n\n\ndef flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SHUFFLE_BUFFER_SIZE = 1024\nBATCH_SIZE = 32\nAUTOTUNE = tf.data.experimental.AUTOTUNE \nCHANNELS = 3\nIMG_SIZE = 128\n\ndef parse_function(filename, label):\n    image_string = tf.io.read_file(filename)\n    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n    image_normalized = image_resized / 255.0\n    return image_normalized, label\n\n","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef create_dataset(filenames, labels, is_training=True):\n\n    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n    \n    if is_training == True:\n        dataset = dataset.cache()\n        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n        \n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n    \n    return dataset\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR = 1e-5 \nEPOCHS = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n#                 'releases/download/v0.2/'\n#                 'resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n# WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n#                        'releases/download/v0.2/'\n#                        'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"IMG_SIZE = (128,128)\n\ndatagen_train = ImageDataGenerator(rescale = 1./255,\n                                featurewise_center=True,\n                                featurewise_std_normalization=True,\n                                rotation_range=20,\n                                width_shift_range=0.2,\n                                height_shift_range=0.2,\n                                horizontal_flip=False,\n                                shear_range=0.2,\n                                zoom_range=0.2,\n                                fill_mode = 'nearest')\n\ndatagen_valid = ImageDataGenerator(rescale = 1./255)\ndatagen_test = ImageDataGenerator(rescale = 1./255)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n# base_model = tf.keras.applications.ResNet50(input_shape=(128,128,3),\n#                                                include_top=False,\n#                                                weights='imagenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# last_layer=base_model.get_layer('conv3_block4_out').output\n# x=tf.keras.layers.Flatten()(last_layer)\n# # x= tf.keras.layers.Dense(16000 , activation = 'relu')(x)\n# x= tf.keras.layers.Dense(3200, activation = 'relu')(x)\n# x= tf.keras.layers.Dense(512,activation = 'relu')(x)\n# x= tf.keras.layers.Dense(64 ,activation = 'relu')(x)\n# x= tf.keras.layers.Dense(15 ,activation = 'relu')(x)\n\n# model = tf.keras.Model(base_model.input , x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # base_model.summary()\n# for layer in model.layers:\n#     layer.trainable=False\n#     if layer.name[-2:]=='bn' or layer.name[:5]=='conv3' or layer.name[:1]=='f' or layer.name[:1]=='d':\n#         layer.trainable=True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.test.is_gpu_available(\n    cuda_only=False,\n    min_cuda_compute_capability=None\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# with tf.device('/gpu:1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = create_dataset(train_df, train_y)\nval_ds = create_dataset(valid_df, valid_y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef macro_soft_f1(y, y_hat):\n    y = tf.cast(y, tf.float32)\n    y_hat = tf.cast(y_hat, tf.float32)\n    tp = tf.reduce_sum(y_hat * y, axis=0)\n    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n    soft_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n    cost = 1 - soft_f1 # reduce 1 - soft-f1 in order to increase soft-f1\n    macro_cost = tf.reduce_mean(cost) # average on all labels\n    return macro_cost\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef macro_f1(y, y_hat, thresh=0.5):\n    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n    \n    Args:\n        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n        thresh: probability value above which we predict positive\n        \n    Returns:\n        macro_f1 (scalar Tensor): value of macro F1 for the batch\n    \"\"\"\n    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n    macro_f1 = tf.reduce_mean(f1)\n    return macro_f1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.compile(\n#   optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n#   loss=macro_soft_f1,\n#   metrics=[macro_f1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import matplotlib.image as mping\n# img = mping.imread(final_paths[0])\n# plt.imshow(img)\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history = model.fit(train_ds,\n#                     epochs=EPOCHS,\n#                     validation_data=create_dataset(valid_df , valid_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.keras.optimizers import RMSprop\n# model.compile(optimizer = RMSprop(lr= 0.001) ,\n#              loss=macro_soft_f1,\n#             metrics=[macro_f1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(datagen_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"history = model.fit_generator(datagen_train,\n                              validation_data=datagen_valid,\n                              steps_per_epoch=200,\n                              epochs=10,\n                              validation_steps=10,\n                              verbose=2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"LR=0.0001","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# with tf.device(\"/gpu:0\"):\n#     train_ds = create_dataset(train_df, train_y)\n#     val_ds = create_dataset(valid_df, valid_y)\nbase_model = tf.keras.applications.ResNet50(input_shape=(128,128,3),\n                                       include_top=False,\n                                       weights='imagenet')\nlast_layer=base_model.get_layer('conv3_block4_out').output\nx=tf.keras.layers.Flatten()(last_layer)\n#     x= tf.keras.layers.Dense(3200, activation = 'relu')(x)\nx= tf.keras.layers.Dense(512,activation = 'relu')(x)\nx = tf.keras.layers.Dropout(0.3)(x)\nx= tf.keras.layers.Dense(64 ,activation = 'relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx= tf.keras.layers.Dense(15 ,activation = 'relu')(x)\nmodel = tf.keras.Model(base_model.input , x)\n# for layer in model.layers:\n#     layer.trainable=False\n#     if layer.name[-2:]=='bn' or layer.name[:5]=='conv3' or layer.name[:1]=='f' or layer.name[:1]=='d':\n#         layer.trainable=True\nfrom tensorflow.keras.optimizers import RMSprop        \nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),loss=macro_soft_f1,metrics=[macro_f1,'acc'])  \nhistory = model.fit(train_ds,\n            epochs=EPOCHS,\n            validation_data=create_dataset(valid_df , valid_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),loss=macro_soft_f1,metrics=[macro_f1,'acc']) ","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_ds,\n            epochs=5,\n            validation_data=create_dataset(valid_df , valid_y))","execution_count":42,"outputs":[{"output_type":"stream","text":"Train for 81 steps, validate for 61 steps\nEpoch 1/5\n81/81 [==============================] - 189s 2s/step - loss: 0.7625 - macro_f1: 0.0671 - acc: 0.0341 - val_loss: 0.9093 - val_macro_f1: 0.0357 - val_acc: 0.0097\nEpoch 2/5\n81/81 [==============================] - 28s 350ms/step - loss: 0.7030 - macro_f1: 0.0949 - acc: 0.0615 - val_loss: 0.8030 - val_macro_f1: 0.0670 - val_acc: 0.0239\nEpoch 3/5\n81/81 [==============================] - 28s 348ms/step - loss: 0.7107 - macro_f1: 0.0900 - acc: 0.0511 - val_loss: 0.9047 - val_macro_f1: 0.0388 - val_acc: 0.0344\nEpoch 4/5\n81/81 [==============================] - 28s 349ms/step - loss: 0.7579 - macro_f1: 0.0786 - acc: 0.0547 - val_loss: 0.7847 - val_macro_f1: 0.0612 - val_acc: 0.0321\nEpoch 5/5\n81/81 [==============================] - 28s 347ms/step - loss: 0.7385 - macro_f1: 0.0742 - acc: 0.0295 - val_loss: 0.8026 - val_macro_f1: 0.0865 - val_acc: 0.0527\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"history1 = model.fit(train_ds,\n            epochs=20,\n            validation_data=create_dataset(valid_df , valid_y))","execution_count":43,"outputs":[{"output_type":"stream","text":"Train for 81 steps, validate for 61 steps\nEpoch 1/20\n81/81 [==============================] - 183s 2s/step - loss: 0.7553 - macro_f1: 0.0720 - acc: 0.0351 - val_loss: 0.9108 - val_macro_f1: 0.0444 - val_acc: 0.0375\nEpoch 2/20\n81/81 [==============================] - 28s 346ms/step - loss: 0.8820 - macro_f1: 0.0393 - acc: 0.0429 - val_loss: 0.8694 - val_macro_f1: 0.0271 - val_acc: 0.0092\nEpoch 3/20\n81/81 [==============================] - 28s 347ms/step - loss: 0.8460 - macro_f1: 0.0350 - acc: 0.0394 - val_loss: 0.8591 - val_macro_f1: 0.0209 - val_acc: 0.0188\nEpoch 4/20\n81/81 [==============================] - 28s 345ms/step - loss: 0.8386 - macro_f1: 0.0402 - acc: 0.0390 - val_loss: 0.8541 - val_macro_f1: 0.0254 - val_acc: 0.0231\nEpoch 5/20\n81/81 [==============================] - 28s 350ms/step - loss: 0.8402 - macro_f1: 0.0324 - acc: 0.0740 - val_loss: 0.9266 - val_macro_f1: 0.0274 - val_acc: 0.0044\nEpoch 6/20\n81/81 [==============================] - 28s 346ms/step - loss: 0.8391 - macro_f1: 0.0445 - acc: 0.0641 - val_loss: 0.7779 - val_macro_f1: 0.0588 - val_acc: 0.0764\nEpoch 7/20\n81/81 [==============================] - 28s 349ms/step - loss: 0.7346 - macro_f1: 0.0790 - acc: 0.1030 - val_loss: 0.7096 - val_macro_f1: 0.0795 - val_acc: 0.1074\nEpoch 8/20\n81/81 [==============================] - 28s 347ms/step - loss: 0.6974 - macro_f1: 0.0910 - acc: 0.1642 - val_loss: 0.7143 - val_macro_f1: 0.0811 - val_acc: 0.1670\nEpoch 9/20\n81/81 [==============================] - 28s 350ms/step - loss: 0.6797 - macro_f1: 0.0925 - acc: 0.1312 - val_loss: 0.7576 - val_macro_f1: 0.0663 - val_acc: 0.0875\nEpoch 10/20\n81/81 [==============================] - 28s 347ms/step - loss: 0.6956 - macro_f1: 0.0781 - acc: 0.1504 - val_loss: 0.8057 - val_macro_f1: 0.0266 - val_acc: 0.1863\nEpoch 11/20\n81/81 [==============================] - 28s 348ms/step - loss: 0.7538 - macro_f1: 0.0646 - acc: 0.1382 - val_loss: 0.8499 - val_macro_f1: 0.0315 - val_acc: 0.1687\nEpoch 12/20\n81/81 [==============================] - 28s 349ms/step - loss: 0.7214 - macro_f1: 0.0657 - acc: 0.1092 - val_loss: 0.9194 - val_macro_f1: 0.0203 - val_acc: 0.0460\nEpoch 13/20\n81/81 [==============================] - 28s 346ms/step - loss: 0.7522 - macro_f1: 0.0437 - acc: 0.0980 - val_loss: 0.8834 - val_macro_f1: 0.0177 - val_acc: 0.1141\nEpoch 14/20\n81/81 [==============================] - 28s 347ms/step - loss: 0.7817 - macro_f1: 0.0385 - acc: 0.0883 - val_loss: 0.8968 - val_macro_f1: 0.0135 - val_acc: 0.1837\nEpoch 15/20\n81/81 [==============================] - 28s 346ms/step - loss: 0.7248 - macro_f1: 0.0608 - acc: 0.1306 - val_loss: 0.7426 - val_macro_f1: 0.0684 - val_acc: 0.1684\nEpoch 16/20\n81/81 [==============================] - 28s 348ms/step - loss: 0.7015 - macro_f1: 0.0826 - acc: 0.1376 - val_loss: 0.7473 - val_macro_f1: 0.0611 - val_acc: 0.1785\nEpoch 17/20\n81/81 [==============================] - 28s 346ms/step - loss: 0.7491 - macro_f1: 0.0481 - acc: 0.1445 - val_loss: 0.8697 - val_macro_f1: 0.0429 - val_acc: 0.1790\nEpoch 18/20\n81/81 [==============================] - 28s 349ms/step - loss: 0.7791 - macro_f1: 0.0468 - acc: 0.1501 - val_loss: 0.7855 - val_macro_f1: 0.0372 - val_acc: 0.1631\nEpoch 19/20\n81/81 [==============================] - 28s 345ms/step - loss: 0.7948 - macro_f1: 0.0380 - acc: 0.1331 - val_loss: 0.8516 - val_macro_f1: 0.0137 - val_acc: 0.1884\nEpoch 20/20\n81/81 [==============================] - 28s 348ms/step - loss: 0.7623 - macro_f1: 0.0576 - acc: 0.1444 - val_loss: 0.8239 - val_macro_f1: 0.0512 - val_acc: 0.1877\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"history3=model.fit(train_ds,\n            epochs=10,\n            validation_data=create_dataset(valid_df , valid_y))","execution_count":null,"outputs":[{"output_type":"stream","text":"Train for 81 steps, validate for 486 steps\nEpoch 1/10\n81/81 [==============================] - 188s 2s/step - loss: 0.7621 - macro_f1: 0.0643 - acc: 0.1442 - val_loss: 0.8202 - val_macro_f1: 0.0527 - val_acc: 0.1812\nEpoch 2/10\n81/81 [==============================] - 31s 381ms/step - loss: 0.7428 - macro_f1: 0.0606 - acc: 0.1437 - val_loss: 0.8118 - val_macro_f1: 0.0503 - val_acc: 0.1716\nEpoch 3/10\n81/81 [==============================] - 31s 381ms/step - loss: 0.7307 - macro_f1: 0.0561 - acc: 0.1444 - val_loss: 0.8159 - val_macro_f1: 0.0422 - val_acc: 0.1658\nEpoch 4/10\n81/81 [==============================] - 31s 380ms/step - loss: 0.7225 - macro_f1: 0.0520 - acc: 0.1423 - val_loss: 0.8169 - val_macro_f1: 0.0400 - val_acc: 0.1580\nEpoch 5/10\n81/81 [==============================] - 31s 381ms/step - loss: 0.7187 - macro_f1: 0.0468 - acc: 0.1388 - val_loss: 0.8370 - val_macro_f1: 0.0326 - val_acc: 0.1616\nEpoch 6/10\n81/81 [==============================] - 31s 381ms/step - loss: 0.7174 - macro_f1: 0.0406 - acc: 0.1394 - val_loss: 0.8670 - val_macro_f1: 0.0247 - val_acc: 0.1648\nEpoch 7/10\n81/81 [==============================] - 31s 384ms/step - loss: 0.7078 - macro_f1: 0.0383 - acc: 0.1405 - val_loss: 0.8730 - val_macro_f1: 0.0231 - val_acc: 0.1708\nEpoch 8/10\n81/81 [==============================] - 31s 384ms/step - loss: 0.6883 - macro_f1: 0.0379 - acc: 0.1375 - val_loss: 0.8711 - val_macro_f1: 0.0230 - val_acc: 0.1701\nEpoch 9/10\n81/81 [==============================] - 31s 383ms/step - loss: 0.7016 - macro_f1: 0.0348 - acc: 0.1408 - val_loss: 0.8834 - val_macro_f1: 0.0199 - val_acc: 0.1746\nEpoch 10/10\n73/81 [==========================>...] - ETA: 2s - loss: 0.6884 - macro_f1: 0.0329 - acc: 0.1441","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}