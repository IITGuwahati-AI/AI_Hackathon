{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n%load_ext autoreload\n\n%autoreload 2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n       # print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":40,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"unexpected EOF while parsing (<ipython-input-40-5a2510698957>, line 18)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-40-5a2510698957>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    # Any results you write to the current directory are saved as output.\u001b[0m\n\u001b[0m                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base = tf.keras.applications.ResNet50(\n    include_top=False,\n    weights='imagenet')\n","execution_count":41,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dir =  \"/kaggle/input/data\"\ntrain = os.listdir(\"/kaggle/input/data\")","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image1 =  os.path.join(dir + \"images_001\")","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from glob import glob \nimport pandas as pd\n\ndataset = pd.read_csv('../input/data/Data_Entry_2017.csv')\npaths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..', 'input', 'data',  'images*', '*', '*.png'))}\nprint('Scans found:', len(paths), ', Total Headers', dataset.shape[0])\ndataset['path'] = dataset['Image Index'].map(paths.get)\ndataset['Cardiomegaly'] = dataset['Finding Labels'].map(lambda x: 'Cardiomegaly' in x)\ndataset['Finding'] = dataset['Finding Labels'].map(lambda x: x != 'No Finding').astype(int)\ndataset['Patient Age'] = np.clip(dataset['Patient Age'], 5, 100)\nlabel_freq = dataset['Finding Labels'].apply(lambda s: str(s).split('|')).explode().value_counts().sort_values(ascending=False)\nrare = list(label_freq[label_freq<10].index)\ndataset['labels'] = dataset['Finding Labels'].apply(lambda s: [l for l in str(s).split('|') if l not in rare])\n\n","execution_count":44,"outputs":[{"output_type":"stream","text":"Scans found: 112120 , Total Headers 112120\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dataset['Finding Labels'] = dataset['Finding Labels'].map(lambda x: x.replace('No Finding', 'n'))\nfrom itertools import chain\nall_labels = np.unique(list(chain(*dataset['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nall_labels = [x for x in all_labels if len(x)>0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        dataset[c_label] = dataset['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\n#dataset.sample(3)\ndataset['disease_vec'] = dataset.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])","execution_count":45,"outputs":[{"output_type":"stream","text":"All Labels (15): ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = dataset[['Image Index' , 'Patient ID', 'path', 'Finding' , 'labels' , 'disease_vec']]","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"noFind = data[data['Finding']==0]['Image Index'].tolist()\nFind = data[data['Finding']==1]['Image Index'].tolist()\nnoFind_path = data[data['Finding']==0]['path'].tolist()\nFind_path = data[data['Finding']==1]['path'].tolist()","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = (glob(os.path.join('..' , 'input' , 'data' , 'images*' , '*' , '*' )))","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #noFind_paths = []\n# #for i in noFind[:10000]:\n#     destination = (glob(os.path.join('..' , 'input' , 'data' , 'images*' , '*' , i )))\n#     noFind_paths.append(destination)","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find_paths = []\n# for i in Find:\n#     destination = (glob(os.path.join('..' , 'input' , 'data' , 'images*' , '*' , i )))\n#     Find_paths.append(destination)","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_paths = Find_path + noFind_path[:10000]\n\nfinal_data = data[data['Finding']==1]\ntemp= data[data['Finding']==0][:10000]\n\n\nfinal_data.append(temp)\nfinal_paths = final_data['path'].tolist()","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\ntrain_df, valid_df , train_y , valid_y = train_test_split(final_paths, \n                                                          final_data['disease_vec'].tolist(),\n                                   test_size = 0.6, \n                                   random_state = 2000,\n                                   #stratify = data['labels'].map(lambda x: x[:4]\n                                     )\n\nvalid_df, test_df , valid_y , test_y = train_test_split(valid_df, \n                                                        valid_y,\n                                   test_size = 0.5, \n                                   random_state = 2000)\n\n\n\ndef flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen\n\n\n\n","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SHUFFLE_BUFFER_SIZE = 1024\nBATCH_SIZE = 32 \nAUTOTUNE = tf.data.experimental.AUTOTUNE \nCHANNELS = 3\nIMG_SIZE = 128\n\ndef parse_function(filename, label):\n    image_string = tf.io.read_file(filename)\n    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n    image_normalized = image_resized / 255.0\n    return image_normalized, label\n\n","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef create_dataset(filenames, labels, is_training=True):\n\n    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n    \n    if is_training == True:\n        dataset = dataset.cache()\n        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n        \n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n    \n    return dataset\n\n","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR = 0.001\nEPOCHS = 1","execution_count":55,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_df","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"IMG_SIZE = (128,128)\n\ndatagen_train = ImageDataGenerator(rescale = 1./255,\n                                featurewise_center=True,\n                                featurewise_std_normalization=True,\n                                rotation_range=20,\n                                width_shift_range=0.2,\n                                height_shift_range=0.2,\n                                horizontal_flip=False,\n                                shear_range=0.2,\n                                zoom_range=0.2,\n                                fill_mode = 'nearest')\n\ndatagen_valid = ImageDataGenerator(rescale = 1./255)\ndatagen_test = ImageDataGenerator(rescale = 1./255)\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"\n\n\ntrain_gen = flow_from_dataframe(datagen_train,train_df , \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 32)\n\nvalid_gen = flow_from_dataframe(datagen_valid, valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 256) \n\nvalid_gen = flow_from_dataframe(datagen_test, test_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 256) \n\n# test_X, test_Y = next(flow_from_dataframe(core_idg, \n#                                valid_df, \n#                              path_col = 'path',\n#                             y_col = 'disease_vec', \n#                             target_size = IMG_SIZE,\n#                              color_mode = 'rgb',\n#                             batch_size = 1024)) # one big batch\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nmodel = tf.keras.models.Sequential([\n                                               tf.keras.layers.Conv2D(16 , (3,3) , activation='relu', input_shape =(128, 128 ,3)),\n                                               tf.keras.layers.MaxPool2D(2,2),\n                                               tf.keras.layers.Conv2D(64 , (3,3) , activation='relu'),\n                                               tf.keras.layers.MaxPool2D(2,2),\n                                               tf.keras.layers.Conv2D(256 , (3,3) , activation='relu'),\n                                               tf.keras.layers.MaxPool2D(2,2),\n                                                tf.keras.layers.Conv2D(512 , (3,3) , activation='relu'),\n                                               tf.keras.layers.MaxPool2D(2,2),  \n                                               tf.keras.layers.Flatten(),\n                                               tf.keras.layers.Dense(128 , activation = 'relu'),\n                                                tf.keras.layers.Dropout(0.25),\n                                               tf.keras.layers.Dense(32 , activation = 'relu'),\n                                                tf.keras.layers.Dropout(0.25),\n                                                tf.keras.layers.Dense(16 , activation = 'relu'),\n                                               tf.keras.layers.Dense(15 , activation = 'sigmoid')\n                                               ])","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = create_dataset(train_df, train_y)\nval_ds = create_dataset(valid_df, valid_y)\ntest_ds = create_dataset(test_df, test_df)\n","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef macro_soft_f1(y, y_hat):\n    y = tf.cast(y, tf.float32)\n    y_hat = tf.cast(y_hat, tf.float32)\n    tp = tf.reduce_sum(y_hat * y, axis=0)\n    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n    soft_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n    cost = 1 - soft_f1\n    macro_cost = tf.reduce_mean(cost)\n    return macro_cost\n","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef macro_f1(y, y_hat, thresh=0.5):\n    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n    macro_f1 = tf.reduce_mean(f1)\n    return macro_f1","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n  optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n  loss=macro_soft_f1,\n  metrics=[macro_f1])","execution_count":61,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import matplotlib.image as mping\n# img = mping.imread(final_paths[0])\n# plt.imshow(img)","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_ds,\n                steps_per_epoch = 155,\n              epochs = 200,\n              validation_steps = 93,\n                    validation_data=create_dataset(valid_df , valid_y))","execution_count":63,"outputs":[{"output_type":"stream","text":"Train for 647 steps, validate for 486 steps\nEpoch 1/20\n647/647 [==============================] - 394s 609ms/step - loss: 0.8344 - macro_f1: 0.1652 - val_loss: 0.8375 - val_macro_f1: 0.1625\nEpoch 2/20\n647/647 [==============================] - 14s 22ms/step - loss: 0.8343 - macro_f1: 0.1658 - val_loss: 0.8806 - val_macro_f1: 0.1194\nEpoch 3/20\n647/647 [==============================] - 14s 22ms/step - loss: 0.8463 - macro_f1: 0.1537 - val_loss: 0.8504 - val_macro_f1: 0.1496\nEpoch 4/20\n647/647 [==============================] - 14s 22ms/step - loss: 0.8613 - macro_f1: 0.1387 - val_loss: 0.9109 - val_macro_f1: 0.0891\nEpoch 5/20\n647/647 [==============================] - 15s 23ms/step - loss: 0.8781 - macro_f1: 0.1219 - val_loss: 0.9461 - val_macro_f1: 0.0539\nEpoch 6/20\n647/647 [==============================] - 14s 22ms/step - loss: 0.9001 - macro_f1: 0.0999 - val_loss: 0.9397 - val_macro_f1: 0.0603\nEpoch 7/20\n647/647 [==============================] - 14s 21ms/step - loss: 0.8893 - macro_f1: 0.1107 - val_loss: 0.9129 - val_macro_f1: 0.0871\nEpoch 8/20\n647/647 [==============================] - 14s 22ms/step - loss: 0.8955 - macro_f1: 0.1045 - val_loss: 0.9192 - val_macro_f1: 0.0808\nEpoch 9/20\n647/647 [==============================] - 14s 22ms/step - loss: 0.9027 - macro_f1: 0.0973 - val_loss: 0.9460 - val_macro_f1: 0.0540\nEpoch 10/20\n647/647 [==============================] - 11s 17ms/step - loss: 0.9053 - macro_f1: 0.0947\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-3161f158e52b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(train_ds,\n\u001b[1;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     validation_data=create_dataset(valid_df , valid_y))\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                       \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                       total_epochs=1)\n\u001b[0m\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m    397\u001b[0m                                  prefix='val_')\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m   \u001b[0mconstant_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \"\"\"\n\u001b[1;32m    821\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \"\"\"\n\u001b[1;32m    941\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict(test_ds[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\nmodel.compile(optimizer = RMSprop(lr= 0.001) ,\n             loss=macro_soft_f1,\n            metrics=[macro_f1 , 'acc'])","execution_count":67,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(datagen_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"history = model.fit_generator(datagen_train,\n                              validation_data=datagen_valid,\n                              steps_per_epoch=200,\n                              epochs=10,\n                              validation_steps=10,\n                              verbose=2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}